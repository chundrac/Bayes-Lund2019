{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an interactive look at code used to run STRUCTURE-style inference for the DiACL data set for some value of K (clusters). This notebook shows code which infers the concentration parameter $\\lambda$ of the component-feature distributions. For other versions, see the python files in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf              #version '1.12.0'\n",
    "import tensorflow_probability as tfp #version '0.5.0'\n",
    "import os\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "import time\n",
    "import pickle as pkl\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude ancient and medieval languages and focus only on contemporary languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_to_exclude = ['Avestan','Classical_Greek','Gothic','Hittite','Latin','Luwian','Middle_Breton', 'Middle_Dutch', 'Middle_English', 'Middle_Greek', 'Middle_High_German', 'Middle_Irish', 'Middle_Low_German', 'Middle_Persian', 'Middle_Welsh','Old_Church_Slavonic', 'Old_Dutch', 'Old_English', 'Old_French', 'Old_Frisian', 'Old_Georgian', 'Old_High_German', 'Old_Irish', 'Old_Italian', 'Old_Norse', 'Old_Persian', 'Old_Portuguese', 'Old_Proven√ßal', 'Old_Prussian', 'Old_Russian', 'Old_Saxon', 'Old_Spanish', 'Old_Swedish','Pali','Prakrit','Sanskrit','Sogdian','Tocharian_A', 'Tocharian_B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function loads the data and variables. Other variables must be specified, such as the number of clusters assumed (this can be done in the command line interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    #load data\n",
    "    f = open('diacl_qualitative_coding.tsv','r')\n",
    "    features = f.read()\n",
    "    f.close()\n",
    "    #convert to list\n",
    "    features = [l.split('\\t') for l in features.split('\\n')]\n",
    "    #get rid of data from ancient/medieval languages\n",
    "    features = [l for l in features if l[0] not in langs_to_exclude]\n",
    "    #sorted list of all unique languages\n",
    "    lang_list = sorted(set([l[0] for l in features]))\n",
    "    #sorted list of all unique feature-variant pairs\n",
    "    feat_var_list = sorted(set([(l[1],l[2]) for l in features]))\n",
    "    #convert data to numeric values\n",
    "    lang_inds = np.array([lang_list.index(l[0]) for l in features],dtype=np.int32)\n",
    "    feat_var_inds = np.array([feat_var_list.index((l[1],l[2])) for l in features],dtype=np.int32)\n",
    "    #number of all features pairs\n",
    "    X = len(sorted(set([l[1] for l in features])))\n",
    "    #number of languages\n",
    "    L = len(lang_list)\n",
    "    #number of all feature,variant pairs\n",
    "    S = len(feat_var_list)\n",
    "    #number of all feature,variant pairs - 1 (for unconstrained parameterization)\n",
    "    S_u = S-X\n",
    "    #length of each distribution in collection\n",
    "    R = [len([l for l in feat_var_list if l[0]==f]) for f in sorted(set([l[1] for l in features]))]\n",
    "    #length of each distribution in collection - 1 (for unconstrained parameterization)\n",
    "    R_u = [r-1 for r in R]\n",
    "    #indices of first and last+1 element in each partition\n",
    "    part = [[0,R[0]]]+[[reduce(lambda x,y:x+y,R[:i]),reduce(lambda x,y:x+y,R[:i+1])] for i in range(1,len(R))]\n",
    "    part_u = [[0,R_u[0]]]+[[reduce(lambda x,y:x+y,R_u[:i]),reduce(lambda x,y:x+y,R_u[:i+1])] for i in range(1,len(R_u))]\n",
    "    #number of datapoints\n",
    "    N = len(features)\n",
    "    return(lang_inds,feat_var_inds,X,L,S,S_u,R,R_u,part,part_u,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function initializes our parameters in unconstrained space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_unconstrained_params(K,L,S_u):\n",
    "    lambda_u = tfd.Uniform(-1.,1.).sample()\n",
    "    alpha_u = tfd.Uniform(-1.,1.).sample()\n",
    "    theta_u = tfd.Uniform(tf.ones([L,K-1])*-1.,tf.ones([L,K-1])*1.).sample()\n",
    "    phi_u = tfd.Uniform(tf.ones([K,S_u])*1.,tf.ones([K,S_u])*1.).sample()\n",
    "    #phi_u = [tfd.Uniform(tf.ones([K,R_u[x]])*-100.,tf.ones([K,R_u[x]])*100.).sample() for x in range(X)]\n",
    "    return(lambda_u,alpha_u,theta_u,phi_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function transforms unconstrained parameters to constrained space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_params(lambda_u,alpha_u,theta_u,phi_u,X,part_u):\n",
    "    lambda_c = tfb.Softplus().forward(lambda_u)\n",
    "    alpha_c = tfb.Softplus().forward(alpha_u)\n",
    "    theta_c = tfb.SoftmaxCentered().forward(theta_u)\n",
    "    phi_c = tf.concat([tfb.SoftmaxCentered().forward(phi_u[:,part_u[x][0]:part_u[x][1]]) for x in range(X)],axis=1)\n",
    "    #phi_c = [tfb.SoftmaxCentered().forward(phi_u[x]) for x in range(X)]\n",
    "    return(lambda_c,alpha_c,theta_c,phi_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function evaluates the log posterior probability of the model under a set of parameter values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_log_prob(lang_array,feat_var_array,K,L,R,X,part,part_u,lambda_u,alpha_u,theta_u,phi_u):\n",
    "    lambda_c,alpha_c,theta_c,phi_c = transform_params(lambda_u,alpha_u,theta_u,phi_u,X,part_u)\n",
    "    #define the priors\n",
    "    lambda_ = tfd.Gamma(1.,1.)\n",
    "    theta = tfd.Dirichlet(tf.ones([L,K])*alpha_c)\n",
    "    phi = [tfd.Dirichlet(tf.ones([R[x]])*lambda_c) for x in range(X)]\n",
    "    #compute log priors\n",
    "    lprior = lambda_.log_prob(lambda_c)\n",
    "    lprior += tf.reduce_sum(theta.log_prob(theta_c))\n",
    "    lprior += tf.reduce_sum([phi[x].log_prob(phi_c[:,part[x][0]:part[x][1]]) for x in range(X)])\n",
    "    #compute log likelihood\n",
    "    llik = tf.reduce_sum(tf.reduce_logsumexp(tf.gather(tf.log(theta_c),lang_array) + tf.gather(tf.log(tf.transpose(phi_c)),feat_var_array),axis=1))\n",
    "    #return log posterior\n",
    "    return(lprior+llik)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs Hamiltonian Monte Carlo for 10000 iterations over a pre-specified number of chains, discarding the first 2000 samples as burn-in and storing every 10th sample. We adapt the step size, shooting for an acceptance ratio of ~ .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(K,chains):\n",
    "    #create step size variable\n",
    "    step_size = tf.get_variable(name='step_size',initializer=1e-5,use_resource=True,trainable=False)\n",
    "    #define HMC transition kernel\n",
    "    n_results = 800\n",
    "    discard = 2000\n",
    "    lang_inds,feat_var_inds,X,L,S,S_u,R,R_u,part,part_u,N = generate_data()\n",
    "    posts = []\n",
    "    for c in range(chains):\n",
    "        #tf.reset_default_graph()\n",
    "        lambda_u,alpha_u,theta_u,phi_u = initialize_unconstrained_params(K,L,S_u)\n",
    "        def target_log_prob_fn(lambda_u,alpha_u,theta_u,phi_u):\n",
    "            return(joint_log_prob(lang_inds,feat_var_inds,K,L,R,X,part,part_u,lambda_u=lambda_u,alpha_u=alpha_u,theta_u=theta_u,phi_u=phi_u))\n",
    "        kernel = tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                    target_log_prob_fn=target_log_prob_fn,\n",
    "                    step_size=step_size,\n",
    "                    step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),\n",
    "                    num_leapfrog_steps=5)\n",
    "        states, kernel_results = tfp.mcmc.sample_chain(\n",
    "            num_results=n_results,num_burnin_steps=discard,num_steps_between_results=10,\n",
    "            current_state=[lambda_u,alpha_u,theta_u,phi_u],\n",
    "            kernel=kernel)\n",
    "        init_op = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            init_op.run()\n",
    "            states_, kernel_results_ = sess.run([states, kernel_results])\n",
    "            print(kernel_results_.is_accepted.mean())\n",
    "            print(sess.run(step_size))\n",
    "        posts.append((states_,kernel_results_))\n",
    "        print('chain {} finished'.format(c))\n",
    "    f = open('posterior_infer_{}.pkl'.format(K),'wb')\n",
    "    pkl.dump(posts,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0503 10:33:37.444922 4416779712 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48375\n",
      "0.007858156\n",
      "chain 0 finished\n",
      "0.47375\n",
      "0.00571527\n",
      "chain 1 finished\n",
      "0.49375\n",
      "0.0026829487\n",
      "chain 2 finished\n",
      "0.49875\n",
      "0.007551533\n",
      "chain 3 finished\n"
     ]
    }
   ],
   "source": [
    "run_inference(K=2,chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
